{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d2a49a0",
   "metadata": {},
   "source": [
    "# models in openai\n",
    "https://platform.openai.com/docs/models/overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f2dfe2",
   "metadata": {},
   "source": [
    "https://platform.openai.com/account/api-keys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ecf58f",
   "metadata": {},
   "source": [
    "# pip install --trusted-host pypi.org --trusted-host pypi.python.org --trusted-host files.pythonhosted.org pip openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7395b31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0c55c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bbffddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing openai module into your openai environment\n",
    "import openai\n",
    "\n",
    "# assigning API KEY to initialize openai environment\n",
    "openai.api_key = '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'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781969b8",
   "metadata": {},
   "source": [
    "# Now you are all set to use OpenAI in your python environment. You can follow the below tutorials to try out OpenAI’s latest models.\n",
    "\n",
    "Table of Contents:\n",
    "\n",
    "1. Prompt Engineering\n",
    "2. Text\n",
    "3. Text Generation\n",
    "4. Text Completion\n",
    "5. Translation\n",
    "6. Summarization\n",
    "7. Retrieve factual information\n",
    "8. Text Conversion\n",
    "9. Chat\n",
    "10. Conversation & Chat Completion\n",
    "12. Image\n",
    "13. Image Generation\n",
    "14. Image Editing\n",
    "15. Audio\n",
    "16. Speech-to-text\n",
    "17. Python\n",
    "18. Fine-tuning\n",
    "19. API error codes\n",
    "20. Prompt Engineering\n",
    "\n",
    "\n",
    "Giving the AI brain a unique set of instructions to increase its intelligence and responsiveness is what AI prompt engineering entails. To comprehend what we want from AI models like ChatGPT or GPT-4, they need to be gently nudged in the right direction. Prompt engineering can help with it. The finest answers from the AI may be ensured by carefully structuring the prompts. Now, prompt engineering doesn’t only happen once. The process of adjusting and experimenting is continuing. When we ask the AI a question, we experiment with varied wording and the addition of unique rules. We seem to be concocting a miraculous concoction of instructions! Let’s take a look at some rules to construct good prompts to generate accurate results for AI.\n",
    "\n",
    "# Some Rules of Prompt Engineering\n",
    "Rule 1: Use latest AI models for your tasks\n",
    "\n",
    "It is important to use latest AI models, because AI models do not tend to give accurate results when they are not updated with recent data. For example, ChatGPT was trained on data dated till September 2021 so it won’t be able to provide you with information after September 2021. Whereas, GPT-4 (or ChatGPT plus) is trained on latest data and is able to generate latest information.\n",
    "\n",
    "Rule 2: Start your prompt with Instructions, and use “”” or ### to separate your input from your instruction.\n",
    "\n",
    "For example,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f75ee1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that takes in string argument as parameter\n",
    "def comp(PROMPT, MaxToken=50, outputs=3):\n",
    "\t# using OpenAI's Completion module that helps execute\n",
    "\t# any tasks involving text\n",
    "\tresponse = openai.Completion.create(\n",
    "\t\t# model name used here is text-davinci-003\n",
    "\t\t# there are many other models available under the\n",
    "\t\t# umbrella of GPT-3\n",
    "\t\tmodel=\"gpt-3.5-turbo\",\n",
    "\t\t# passing the user input\n",
    "\t\tprompt=PROMPT,\n",
    "\t\t# generated output can have \"max_tokens\" number of tokens\n",
    "\t\tmax_tokens=MaxToken,\n",
    "\t\t# number of outputs generated in one call\n",
    "\t\tn=outputs\n",
    "\t)\n",
    "\t# creating a list to store all the outputs\n",
    "\toutput = list()\n",
    "\tfor k in response['choices']:\n",
    "\t\toutput.append(k['text'].strip())\n",
    "\treturn output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf35bec",
   "metadata": {},
   "source": [
    "Here we generated text for the user prompt using the Completions module from the OpenAI library. These are the crucial variables related to the Completions module:\n",
    "\n",
    "model [required]: The following openai command can be used to determine the ID of the model to openai.Model.list().data with the model name as the value of the ‘id’ field. We must choose a model that will work for us.\n",
    "\n",
    "prompt: The prompt(s) to generate completions for, encoded as a string, array of strings, array of tokens, or array of token \n",
    "arrays. Note that <|endoftext|> is the document separator that the model sees during training, so if a prompt is not specified the model will generate as if from the beginning of a new document.\n",
    "\n",
    "max_tokens: The maximum number of tokens that the completion will generate. 16 is the default value for the parameter.\n",
    "\n",
    "temperature: The range of the sampling temperature is 0 to 2. In contrast to lower values like 0.2, higher values like 0.8 will result in a more focused and deterministic output.\n",
    "\n",
    "n: The number of answers to produce for each prompt.\n",
    "Example prompts for Text Generation\n",
    "\n",
    "# Now let’s try some prompts for Text Generation using Completions module(Chatgpt with Python).\n",
    "\n",
    "# Prompt 1:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "71eae6c8",
   "metadata": {},
   "source": [
    "fortokeneg=\"data sceince and statistical analysis\"\n",
    "indicator: \"\"\"precise intsruction ###specific instruction###\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d105f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = \"\"\"Write a story to inspire greatness, take the antagonist as a Rabbit and protagnist as turtle.\n",
    "Let antagonist and protagnist compete against each other for a common goal.\n",
    "Story should atmost have 3 lines.\n",
    "\"\"\"\n",
    "comp(PROMPT, MaxToken=3000, outputs=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5312374",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Client: \"This bottle of wine is more sour than my bank account!\"\\nBusinessman: \"Patience, gentle sir: for wine in its nature is far more wise than strange men.\"\\n\\nClient: \"Clearly, the bitterness of this bottle is more palpable than my opinion.\"\\nBusinessman: \"Verily, \\'tis the fortune of your taste that it be so unappeased.\"']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PROMPT = \"\"\"Write a short conversation between client and businessman about a wine bottle purchase.\n",
    "Client is not happy with the purchase and the businessman is not accepting his mistake.\n",
    "Make the conversation sarcastic.\n",
    "Each Response should have atmost 2 lines.\n",
    "The client should talk like Kevin Hart and businessman should talk like Shakespeare.\n",
    "\"\"\"\n",
    "comp(PROMPT, MaxToken=3000, outputs=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfdb52a2",
   "metadata": {},
   "source": [
    "# Example prompts for Text Completion\n",
    "Now let’s try some prompts for Text Completion using Completions module.\n",
    "\n",
    "Prompt 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b2eeb4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"No worries! How about I give you an old-fashioned canteen instead? It's much more durable, and perfect for any outdoor adventures you have planned.\"]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PROMPT = \"\"\"Complete the below conversation between a client and a worker.\n",
    "Make the conversation have a wholesome plot twist.\n",
    "Conversation : ###\n",
    "Client: I want a water bottle.\n",
    "Worker: I don't have any water botlles.\n",
    "Client: But I want water bottles.\n",
    "Worker:\n",
    "###\n",
    "\"\"\"\n",
    "comp(PROMPT, MaxToken=3000, outputs=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ded5f7",
   "metadata": {},
   "source": [
    "Prompt 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "195cb768",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Midas, as proud and arrogant as he was, asked for everything he touched to turn to gold. The angel with a sad face, granted his wish, and it came true immediately.\\nMidas was happy in the beginning as he could make gold wherever he went, but soon his greed led to consequences. He found out that he could not eat and drink anything.\\nHe could not even hug his daughter as everything he touched turned into gold. Midas realised that he was a fool to wish for something so foolish and he began to weep.\\n\\nThe angel appeared again and offered to remove the wish, but with a warning. She warned him about his arrogance and greed and told him to be wise and careful in his decisions. Midas accepted the wisdom and thanked the angel.\\n\\nMidas began to live a more balanced life, appreciating the blessings he already had and being careful of what he wished for in the future. He gave away most of his gold and found peace within himself. From then on, Midas dedicated his life to helping the poor and those in need, all the while learning the lessons of humility and gratitude.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PROMPT = \"\"\"\n",
    "Complete the below story.\n",
    "Story should focus on a moral value like Greed, Wrath, Pride, Arrogance, Sloth or Envy.\n",
    "\n",
    "Story:###\n",
    "Once upon a time, there was a Greek King, Midas.\n",
    "He was very rich and had lots of Gold. He had a daughter, who he loved a lot.\n",
    "One day, Midas found an angel in need of help. He helped her and in return she agreed to grant a wish.\n",
    "###\n",
    "\"\"\"\n",
    "comp(PROMPT, MaxToken=3000, outputs=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe5c424",
   "metadata": {},
   "source": [
    "# Example prompts for Translation\n",
    "Now let’s try some prompts for Translation using Completions module.\n",
    "\n",
    "Prompt 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70395661",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Japanese: 私はOpenAI Python APIについて学んでいます。\\nHindi: मैं OpenAI Python API के बारे में सीख रहा हूँ।']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PROMPT = \"\"\"\n",
    "Translate the below text in Japanese and Hindi.\n",
    "Text:###\n",
    "I am learning about OpenAI Python API.\n",
    "###\n",
    "\"\"\"\n",
    "comp(PROMPT, MaxToken=3000, outputs=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f883bc27",
   "metadata": {},
   "source": [
    "Prompt 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d917b5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"German: Ich lerne über OpenAI Python API.\\nFrench: J'apprends à utiliser l'API Python OpenAI.\"]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PROMPT = \"\"\"\n",
    "Translate the below text in German and French.\n",
    "Text:###\n",
    "I am learning about OpenAI Python API.\n",
    "###\n",
    "\"\"\"\n",
    "comp(PROMPT, MaxToken=3000, outputs=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae41507",
   "metadata": {},
   "source": [
    "# Example prompts for Summarization\n",
    "Now let’s try some prompts for Summarization using Completions module.\n",
    "\n",
    "Prompt 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4d3f4084",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A hare and a tortoise decide to have a race to establish the better one. The hare starts off more quickly, becoming overconfident and taking a nap. The determined and dedicated tortoise eventually wins, exhibiting humility instead of arrogance.']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PROMPT = \"\"\"\n",
    "Summarize the below text and extract the key points.\n",
    "Text:###\n",
    "This is an extremely popular story about a hare and a tortoise.\n",
    "The hare is an animal that is known to move quickly, while a tortoise is one to move slowly.\n",
    "One day, the hare challenged the tortoise to a race simply to prove that he was the best. The tortoise agreed.\n",
    "Once the race began the hare was easily able to get a head start. Upon realizing that the tortoise is far behind. The overconfident hare decided to take a nap.\n",
    "Meanwhile the tortoise, who was extremely determined and dedicated to the race was slowly nearing the finish line.\n",
    "The tortoise won the race while the hare napped. Most importantly he did it with humility and without arrogance.\n",
    "###\n",
    "\"\"\"\n",
    "comp(PROMPT, MaxToken=3000, outputs=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e15b62",
   "metadata": {},
   "source": [
    "Prompt 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5140354a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['- A farmer instructs his son to take their herd of sheep out to graze every day\\n- The son gets bored and cries out \"Wolf! Wolf!\" in order to cause some commotion, even though there is no wolf\\n-The villagers become furious with the boy for creating chaos unnecessarily\\n-The boy shouts \"Wolf!\" for a third time when there is an actual wolf attack, but the villagers do not come to his aid, believing that he is lying again']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PROMPT = \"\"\"\n",
    "Summarize the below text in bullet points.\n",
    "Text:###\n",
    "A farmer asked his son to take their herd of sheep grazing every day.\n",
    "While the boy watched over the sheep, he got bored and decided to have some fun.\n",
    "So, he shouted, “Wolf! Wolf!”. Upon hearing this the villagers ran to help him chase the Wolf away.\n",
    "As they reached him, they realized that there was no Wolf and he was just kidding.\n",
    "The villagers were furious and they yelled at the boy for creating chaos and panic.\n",
    "On the next day and the boy shouted “Wolf!” again and once again the villagers came to help him and saw that there was no wolf.\n",
    "This made them very angry again.\n",
    "On the same day, the boy saw an actual Wolf that has terrorizing the sheep.\n",
    "The boy cried “Wolf! Wolf! please help me” and no villagers showed up as they believed that the boy was joking again.\n",
    "###\n",
    "\"\"\"\n",
    "comp(PROMPT, MaxToken=3000, outputs=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf892057",
   "metadata": {},
   "source": [
    "# Example prompts for Retrieving factual information\n",
    "Now let’s try some prompts for Retrieving factual information using Completions module.\n",
    "\n",
    "Prompt 1:Example prompts for Retrieving factual information\n",
    "Now let’s try some prompts for Retrieving factual information using Completions module.\n",
    "\n",
    "Prompt 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d7e6a0e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['India consists of 28 states and 8 union territories as of 2020:\\n\\nStates:\\n\\n1. Andhra Pradesh\\n2. Arunachal Pradesh\\n3. Assam\\n4. Bihar\\n5. Chhattisgarh\\n6. Goa\\n7. Gujarat\\n8. Haryana\\n9. Himachal Pradesh\\n10. Jammu and Kashmir\\n11. Jharkhand\\n12. Karnataka\\n13. Kerala\\n14. Madhya Pradesh\\n15. Maharashtra\\n16. Manipur\\n17. Meghalaya\\n18. Mizoram\\n19. Nagaland\\n20. Odisha\\n21. Punjab\\n22. Rajasthan\\n23. Sikkim\\n24. Tamil Nadu\\n25. Telangana\\n26. Tripura\\n27. Uttarakhand\\n28. Uttar Pradesh\\n\\nUnion Territories: \\n\\n1. Andaman and Nicobar Islands\\n2. Chandigarh\\n3. Dadra and Nagar Haveli\\n4. Daman and Diu\\n5. Delhi\\n6. Lakshadweep\\n7. Ladakh\\n8. Puducherry']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PROMPT = \"\"\"\n",
    "What all states and union teritories are in India?\n",
    "\"\"\"\n",
    "comp(PROMPT, MaxToken=3000, outputs=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "29329ad3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['As of 2021, Dwayne Johnson, best known as The Rock, is the highest paid actor in the world, reportedly earning an estimated $87.5 million in 2020.']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PROMPT = \"\"\"\n",
    "Who is the highest paid actor in the world?\n",
    "\"\"\"\n",
    "comp(PROMPT, MaxToken=3000, outputs=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ca04a1",
   "metadata": {},
   "source": [
    "# Example prompts for Text Conversion\n",
    "Now let’s try some prompts for Text Conversion using Completions module.\n",
    "\n",
    "# Prompt 1:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab4e14d",
   "metadata": {},
   "source": [
    "prompt which as an argument=\"\"\"first set of instructions###special instructions 2###\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be28ef29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 🧙‍♂️ of 🌈\n",
      "2. 🎭 🧩\n",
      "3. 🔮 🏃‍♀️\n"
     ]
    }
   ],
   "source": [
    "PROMPT = \"\"\"\n",
    "Convert the below movie titles in emojis\n",
    "Movies List:###\n",
    "1. Wizard of Oz\n",
    "2. The imitation game\n",
    "3. Ghosted\n",
    "###\n",
    "\"\"\"\n",
    "print(comp(PROMPT, MaxToken=3000, outputs=1)[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16d0a7e",
   "metadata": {},
   "source": [
    "# Prompt 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6b24c458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 㔹㔻㔹㔶㔻㔶㔾\n",
      "2. 㔶㔹\n",
      "3. 㔹㔸㔹㔻㔼㔶㔳\n"
     ]
    }
   ],
   "source": [
    "PROMPT = \"\"\"\n",
    "Encode the below texts in only special characters\n",
    "Text:###\n",
    "1. Sessions \n",
    "2. on\n",
    "3. OPENAI\n",
    "###\n",
    "\"\"\"\n",
    "print(comp(PROMPT, MaxToken=3000, outputs=1)[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f419234d",
   "metadata": {},
   "source": [
    "# Chat\n",
    "For performing any chat specific tasks you can define the following function and execute it with your desired prompts."
   ]
  },
  {
   "cell_type": "raw",
   "id": "47682af8",
   "metadata": {},
   "source": [
    "# function that takes in string argument as parameter\n",
    "def comp(PROMPT, MaxToken=50, outputs=3):\n",
    "\t# using OpenAI's Completion module that helps execute\n",
    "\t# any tasks involving text\n",
    "\tresponse = openai.Completion.create(\n",
    "\t\tmodel=\"text-davinci-003\",\n",
    "\t\tprompt=PROMPT,\n",
    "\t\tmax_tokens=MaxToken,\n",
    "\t\tn=outputs\n",
    "\t)\n",
    "\t# creating a list to store all the outputs\n",
    "\toutput = list()\n",
    "\tfor k in response['choices']:\n",
    "\t\toutput.append(k['text'].strip())\n",
    "\treturn output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c508b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that takes in string argument as parameter\n",
    "def chat(MSGS, MaxToken=50, outputs=3):\n",
    "\t# We use the Chat Completion endpoint for chat like inputs\n",
    "\tresponse = openai.ChatCompletion.create(\n",
    "\t# model used here is ChatGPT\n",
    "\t# You can use all these models for this endpoint:\n",
    "\t# gpt-4, gpt-4-0314, gpt-4-32k, gpt-4-32k-0314,\n",
    "\t# gpt-3.5-turbo, gpt-3.5-turbo-0301\n",
    "\tmodel=\"gpt-3.5-turbo\",\n",
    "\tmessages=MSGS,\n",
    "\t# max_tokens generated by the AI model\n",
    "\t# maximu value can be 4096 tokens for \"gpt-3.5-turbo\"\n",
    "\tmax_tokens = MaxToken,\n",
    "\t# number of output variations to be generated by AI model\n",
    "\tn = outputs,\n",
    "\t)\n",
    "\treturn response.choices[0].message\n",
    "\n",
    "# Messages must consist of a collection of message objects,\n",
    "# each of which includes a role (either \"system,\" \"user,\" or \"assistant\")\n",
    "# and a content field for the message's actual text.\n",
    "# Conversations might last only 1 message or span several pages.\n",
    "MSGS = [\n",
    "\t\t{\"role\": \"system\", \"content\": \"<message generated by system>\"},\n",
    "\t\t{\"role\": \"user\", \"content\": \"<message generated by user>\"},\n",
    "\t\t{\"role\": \"assistant\", \"content\": \"<message generated by assistant>\"}\n",
    "\t]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc33f9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary= {key1:value1, key2:value2}"
   ]
  },
  {
   "cell_type": "raw",
   "id": "adc3e6af",
   "metadata": {},
   "source": [
    "Monika: What is the temperature of Noida\n",
    "XYZ: The temperature of Noids is 32 degrees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1519d28",
   "metadata": {},
   "source": [
    "Here, we have used the ChatCompletion module from OpenAI library to execute chat specific tasks using ChatGPT model. Here are the important parameters involved with ChatCompletion module:\n",
    "\n",
    "model [required]: ID of the appropriate model. For information on which models are compatible with the Chat API, go to the model endpoint compatibility table (https://platform.openai.com/docs/models/model-endpoint-compatibility).\n",
    "message: A chronological list of the conversation’s messages. The list of objects must contain dictionary with the following parameters only:\n",
    "Role: The role of the author of this message. It can be either of “system”, “user”, or “assistant”.\n",
    "Content: The contents of the message.\n",
    "max_tokens: The maximum number of tokens to generate in the completion. The default value is 16.\n",
    "temperature: Sampling temperature ranges between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.\n",
    "n: number of completions to generate for each prompt.\n",
    "Examples for Chat Completion\n",
    "Now Let’s see some examples to gain a better understanding of the ChatCompletion API\n",
    "\n",
    "Prompt 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa82614",
   "metadata": {},
   "outputs": [],
   "source": [
    "ch = [\n",
    "\t\t{\"role\": \"user\", \"content\": \"When did India win the world cup\"}\n",
    "\t]\n",
    "\n",
    "chat(ch, MaxToken=500, outputs=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa300d45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject at 0x250006bb950> JSON: {\n",
       "  \"role\": \"assistant\",\n",
       "  \"content\": \"Certainly! Here are some popular chocolate brand names:\\n\\n1. Lindt\\n2. Ghirardelli\\n3. Godiva\\n4. Cadbury\\n5. Hershey's\\n6. Ferrero Rocher\\n7. Toblerone\\n8. Milka\\n9. Nestl\\u00e9\\n10. Patchi\\n\\nThese brands offer a variety of delicious chocolates and have become well-known for their quality and taste.\"\n",
       "}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ch = [\n",
    "\t\t{\"role\": \"user\", \"content\": \"Do you live with Snow White?\"},\n",
    "\t{\"role\": \"assistant\", \"content\": \"No, I live with Willy Wonka in the chocoalte factory.\"},\n",
    "\t{\"role\": \"user\", \"content\": \"Can you tell me some good chocolate names?\"}\n",
    "\n",
    "\t]\n",
    "\n",
    "chat(ch, MaxToken=500, outputs=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32e7540",
   "metadata": {},
   "source": [
    "\n",
    "# Image\n",
    "We can perform Image generation and Image editing using DALL-E model of OpenAI. Before we begin, let’s import some image-processing libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5211a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing other libraries\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "#import openai if using it in a new notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ab2b86",
   "metadata": {},
   "source": [
    "Now we construct a function to produce an image using the DALL E API’s “create” endpoint.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "806c5850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for text-to-image generation\n",
    "# using create endpoint of DALL-E API\n",
    "# function takes in a string argument\n",
    "def generate(text):\n",
    "    res = openai.Image.create(\n",
    "\t# text describing the generated image\n",
    "\tprompt=text,\n",
    "\t# number of images to generate\n",
    "\tn=1,\n",
    "\t# size of each generated image\n",
    "\tsize=\"256x256\",\n",
    "    )\n",
    "# returning the URL of one image as\n",
    "# we are generating only one image\n",
    "    return res[\"data\"][0][\"url\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c2d6aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91ece8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assigning API KEY to initialize openai environment\n",
    "openai.api_key = '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'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76bf792d",
   "metadata": {},
   "source": [
    "An argument string is passed to the API endpoint by the aforementioned function. Other parameters are n (the “number of images generated using that prompt”) and size (the “size of the image generated”). Either Base64 or a URL can be used by the API to generate an image. As output, API provides the created image’s URL."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91968446",
   "metadata": {},
   "source": [
    "# Examples for Image Generation\n",
    "Now Let’s see some examples to gain a better understanding of Image Generation using DALL-E\n",
    "\n",
    "Prompt 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "80527bf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\monika201103\\\\Generative AI- OpenAI'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3e97decd",
   "metadata": {},
   "source": [
    "# prompt describing the desired image\n",
    "text = \"batman in red and blue color\"\n",
    "# calling the custom function \"generate\"\n",
    "# saving the output in \"url1\"\n",
    "url1 = generate(text)\n",
    "# using requests library to get the image in bytes\n",
    "response = requests.get(url1, stream=True)\n",
    "# using the Image module from PIL library to view the image\n",
    "Image.open(response.raw)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d0ea27",
   "metadata": {},
   "source": [
    "Prompt 2"
   ]
  },
  {
   "cell_type": "raw",
   "id": "99c8b46a",
   "metadata": {},
   "source": [
    "# text prompt describing my desired image\n",
    "text = \"a scenic view of moon shining light on a yacht\"\n",
    "# generate function uses DALL-E API to generate image\n",
    "# it returns a temporary URL of the image\n",
    "url1 = generate(text)\n",
    "# We use the requests library to fetch the image from URL\n",
    "response = requests.get(url1, stream=True)\n",
    "# We use the Image Class from PIL library to open the image\n",
    "Image.open(response.raw)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69a6bf0",
   "metadata": {},
   "source": [
    "\n",
    "# Examples for Image Editing\n",
    "For editing the image we use the create edit endpoint of the DALL-E API. In this section, a mask will be uploaded and a text prompt will be supplied in order to change an image. Where the image should be altered is indicated by the transparent portions of the mask, and the prompt should describe the entire new image rather than just the area that was erased.\n",
    "\n",
    "Make sure your image and mask are of the same size (square PNG) and less than 4MB in size before passing them as arguments to API. For this we use the below code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b176efe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\monika201103\\\\Generative AI- OpenAI'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "61930b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(url1)\n",
    "# saving the image in PNG format\n",
    "with open(\"img.png\", \"wb\") as f:\n",
    "    f.write(response.content)\n",
    "# opening the saved image and converting it into \"RGBA\" format\n",
    "# converted image is saved in result\n",
    "result = Image.open('img.png').convert('RGBA')\n",
    "# saving the new image in PNG format\n",
    "result.save('img_rgba.png','PNG')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569d1468",
   "metadata": {},
   "source": [
    "Also, write a prompt such that it describes the full new image not just the transparent area that needs to be replaced. Use the following lines of code to edit the image.\n",
    "\n",
    "Let’s see the example to gain a better understanding of Image Editing using DALL-E.\n",
    "\n",
    "Image 1:\n",
    "\n",
    "We will be using the below image as input:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f29826e",
   "metadata": {},
   "source": [
    "Below is the code for editing the image and generating 3 images as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8624f9bf",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidRequestError",
     "evalue": "Invalid input image - format must be in ['RGBA', 'LA', 'L'], got RGB.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# using create_edit endpoint of the DALL - E API\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_edit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# opening original image in read mode\u001b[39;49;00m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimg_rgba.png\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# opening mask image in read mode\u001b[39;49;00m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmask.png\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# text prompt describing the new image\u001b[39;49;00m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgotham city skyline behind batman\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# number of images to be generated\u001b[39;49;00m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#size of each image generated in pixels\u001b[39;49;00m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m256x256\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# saving the URLs of all image in new variable \"res\"\u001b[39;00m\n\u001b[0;32m     16\u001b[0m res \u001b[38;5;241m=\u001b[39m response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\openai\\api_resources\\image.py:237\u001b[0m, in \u001b[0;36mImage.create_edit\u001b[1;34m(cls, image, mask, api_key, api_base, api_type, api_version, organization, **params)\u001b[0m\n\u001b[0;32m    224\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error\u001b[38;5;241m.\u001b[39mInvalidAPIType(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEdits are not supported by the Azure OpenAI API yet.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    226\u001b[0m requestor, url, files \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_create_edit(\n\u001b[0;32m    227\u001b[0m     image,\n\u001b[0;32m    228\u001b[0m     mask,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    234\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[0;32m    235\u001b[0m )\n\u001b[1;32m--> 237\u001b[0m response, _, api_key \u001b[38;5;241m=\u001b[39m \u001b[43mrequestor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfiles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfiles\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m util\u001b[38;5;241m.\u001b[39mconvert_to_openai_object(\n\u001b[0;32m    240\u001b[0m     response, api_key, api_version, organization\n\u001b[0;32m    241\u001b[0m )\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\openai\\api_requestor.py:298\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[1;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[0;32m    278\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    279\u001b[0m     method,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    286\u001b[0m     request_timeout: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    287\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m    288\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_raw(\n\u001b[0;32m    289\u001b[0m         method\u001b[38;5;241m.\u001b[39mlower(),\n\u001b[0;32m    290\u001b[0m         url,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    296\u001b[0m         request_timeout\u001b[38;5;241m=\u001b[39mrequest_timeout,\n\u001b[0;32m    297\u001b[0m     )\n\u001b[1;32m--> 298\u001b[0m     resp, got_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    299\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resp, got_stream, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\openai\\api_requestor.py:700\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[1;34m(self, result, stream)\u001b[0m\n\u001b[0;32m    692\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m    693\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interpret_response_line(\n\u001b[0;32m    694\u001b[0m             line, result\u001b[38;5;241m.\u001b[39mstatus_code, result\u001b[38;5;241m.\u001b[39mheaders, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    695\u001b[0m         )\n\u001b[0;32m    696\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m parse_stream(result\u001b[38;5;241m.\u001b[39miter_lines())\n\u001b[0;32m    697\u001b[0m     ), \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    698\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    699\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m--> 700\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response_line\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    701\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    702\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    703\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    704\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    705\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m    706\u001b[0m         \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    707\u001b[0m     )\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\openai\\api_requestor.py:763\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[1;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[0;32m    761\u001b[0m stream_error \u001b[38;5;241m=\u001b[39m stream \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mdata\n\u001b[0;32m    762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream_error \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m rcode \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m:\n\u001b[1;32m--> 763\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_error_response(\n\u001b[0;32m    764\u001b[0m         rbody, rcode, resp\u001b[38;5;241m.\u001b[39mdata, rheaders, stream_error\u001b[38;5;241m=\u001b[39mstream_error\n\u001b[0;32m    765\u001b[0m     )\n\u001b[0;32m    766\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[1;31mInvalidRequestError\u001b[0m: Invalid input image - format must be in ['RGBA', 'LA', 'L'], got RGB."
     ]
    }
   ],
   "source": [
    "# using create_edit endpoint of the DALL - E API\n",
    "response = openai.Image.create_edit(\n",
    "    # opening original image in read mode\n",
    "    image=open(\"img_rgba.png\", \"rb\"),\n",
    "    # opening mask image in read mode\n",
    "    mask=open(\"mask.png\", \"rb\"),\n",
    "    # text prompt describing the new image\n",
    "    prompt=\"gotham city skyline behind batman\",\n",
    "    # number of images to be generated\n",
    "    n=1,\n",
    "    #size of each image generated in pixels\n",
    "    size=\"256x256\"\n",
    "    )\n",
    "\n",
    "# saving the URLs of all image in new variable \"res\"\n",
    "res = response['data']\n",
    "\n",
    "# loop to save and display images\n",
    "for i in range(len(res)):\n",
    "# saving URL of image in res\n",
    "    image_url = res[i]['url']\n",
    "    # extracting image from URL in bytes form\n",
    "    response = requests.get(image_url, stream=True)\n",
    "    # opening the image\n",
    "    k = Image.open(response.raw)\n",
    "    # displaying the image\n",
    "    k.show()\n",
    "    # saving the image\n",
    "    with open(f\"img_mask_edit_{i}.png\", \"wb\") as f:\n",
    "        f.write(response.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7bfc19a",
   "metadata": {},
   "source": [
    "Below is the code for editing the image and generating 3 images as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0531d591",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidRequestError",
     "evalue": "Invalid input image - format must be in ['RGBA', 'LA', 'L'], got RGB.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# using create_edit endpoint of the DALL - E API\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_edit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;43;03m# opening original image in read mode\u001b[39;49;00m\n\u001b[0;32m      4\u001b[0m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimg_rgba.png\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;43;03m# opening mask image in read mode\u001b[39;49;00m\n\u001b[0;32m      6\u001b[0m \u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmask.png\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;43;03m# text prompt describing the new image\u001b[39;49;00m\n\u001b[0;32m      8\u001b[0m \u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgotham city skyline behind batman\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;43;03m# number of images to be generated\u001b[39;49;00m\n\u001b[0;32m     10\u001b[0m \u001b[43mn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;43;03m#size of each image generated in pixels\u001b[39;49;00m\n\u001b[0;32m     12\u001b[0m \u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m256x256\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m     13\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# saving the URLs of all image in new variable \"res\"\u001b[39;00m\n\u001b[0;32m     16\u001b[0m res \u001b[38;5;241m=\u001b[39m response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\openai\\api_resources\\image.py:237\u001b[0m, in \u001b[0;36mImage.create_edit\u001b[1;34m(cls, image, mask, api_key, api_base, api_type, api_version, organization, **params)\u001b[0m\n\u001b[0;32m    224\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error\u001b[38;5;241m.\u001b[39mInvalidAPIType(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEdits are not supported by the Azure OpenAI API yet.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    226\u001b[0m requestor, url, files \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_create_edit(\n\u001b[0;32m    227\u001b[0m     image,\n\u001b[0;32m    228\u001b[0m     mask,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    234\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[0;32m    235\u001b[0m )\n\u001b[1;32m--> 237\u001b[0m response, _, api_key \u001b[38;5;241m=\u001b[39m \u001b[43mrequestor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfiles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfiles\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m util\u001b[38;5;241m.\u001b[39mconvert_to_openai_object(\n\u001b[0;32m    240\u001b[0m     response, api_key, api_version, organization\n\u001b[0;32m    241\u001b[0m )\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\openai\\api_requestor.py:298\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[1;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[0;32m    278\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    279\u001b[0m     method,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    286\u001b[0m     request_timeout: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    287\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m    288\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_raw(\n\u001b[0;32m    289\u001b[0m         method\u001b[38;5;241m.\u001b[39mlower(),\n\u001b[0;32m    290\u001b[0m         url,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    296\u001b[0m         request_timeout\u001b[38;5;241m=\u001b[39mrequest_timeout,\n\u001b[0;32m    297\u001b[0m     )\n\u001b[1;32m--> 298\u001b[0m     resp, got_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    299\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resp, got_stream, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\openai\\api_requestor.py:700\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[1;34m(self, result, stream)\u001b[0m\n\u001b[0;32m    692\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m    693\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interpret_response_line(\n\u001b[0;32m    694\u001b[0m             line, result\u001b[38;5;241m.\u001b[39mstatus_code, result\u001b[38;5;241m.\u001b[39mheaders, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    695\u001b[0m         )\n\u001b[0;32m    696\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m parse_stream(result\u001b[38;5;241m.\u001b[39miter_lines())\n\u001b[0;32m    697\u001b[0m     ), \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    698\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    699\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m--> 700\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response_line\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    701\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    702\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    703\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    704\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    705\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m    706\u001b[0m         \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    707\u001b[0m     )\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\openai\\api_requestor.py:763\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[1;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[0;32m    761\u001b[0m stream_error \u001b[38;5;241m=\u001b[39m stream \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mdata\n\u001b[0;32m    762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream_error \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m rcode \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m:\n\u001b[1;32m--> 763\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_error_response(\n\u001b[0;32m    764\u001b[0m         rbody, rcode, resp\u001b[38;5;241m.\u001b[39mdata, rheaders, stream_error\u001b[38;5;241m=\u001b[39mstream_error\n\u001b[0;32m    765\u001b[0m     )\n\u001b[0;32m    766\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[1;31mInvalidRequestError\u001b[0m: Invalid input image - format must be in ['RGBA', 'LA', 'L'], got RGB."
     ]
    }
   ],
   "source": [
    "# using create_edit endpoint of the DALL - E API\n",
    "response = openai.Image.create_edit(\n",
    "# opening original image in read mode\n",
    "image=open(\"img_rgba.png\", \"rb\"),\n",
    "# opening mask image in read mode\n",
    "mask=open(\"mask.png\", \"rb\"),\n",
    "# text prompt describing the new image\n",
    "prompt=\"gotham city skyline behind batman\",\n",
    "# number of images to be generated\n",
    "n=1,\n",
    "#size of each image generated in pixels\n",
    "size=\"256x256\"\n",
    ")\n",
    "\n",
    "# saving the URLs of all image in new variable \"res\"\n",
    "res = response['data']\n",
    "\n",
    "# loop to save and display images\n",
    "for i in range(len(res)):\n",
    "    # saving URL of image in res\n",
    "    image_url = res[i]['url']\n",
    "    # extracting image from URL in bytes form\n",
    "    response = requests.get(image_url, stream=True)\n",
    "    # opening the image\n",
    "    k = Image.open(response.raw)\n",
    "    # displaying the image\n",
    "    k.show()\n",
    "    # saving the image\n",
    "    with open(f\"img_mask_edit_{i}.png\", \"wb\") as f:\n",
    "        f.write(response.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4736bd68",
   "metadata": {},
   "source": [
    "# Audio\n",
    "# There are 2 modules available for Whisper module:\n",
    "\n",
    "1. Transcribe: This module transcribes your audio file into the input language. Model parameters for this module are:\n",
    "\n",
    "file [required]: The audio file to transcribe, in one of these formats: mp3, mp4, mpeg, mpga, m4a, wav, or webm.\n",
    "model [required]: ID of the model to use. Only whisper-1 is currently available.\n",
    "prompt [optional]: An optional text to guide the model’s style or continue a previous audio segment. The prompt should match the audio language.\n",
    "response_format [optional]: The format of the transcript output, in one of these options: json, text, srt, verbose_json, or vtt.\n",
    "temperature [optional]: The sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. If set to 0, the model will use log probability to automatically increase the temperature until certain thresholds are hit.\n",
    "language [optional]: The language of the input audio. Supplying the input language in ISO-639-1 format will improve accuracy and latency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b21bee6",
   "metadata": {},
   "source": [
    "https://drive.google.com/file/d/1jwPYV4-FbFZBKf4zFM43I7Mw-h0ibsnE/view?usp=sharing download audio from here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41d2198",
   "metadata": {},
   "source": [
    "# Examples for Audio Transcribing\n",
    "Audio we will be using for trying out Transcribe module:\n",
    "\n",
    "Audio Player\n",
    "\n",
    "00:00\n",
    "00:00\n",
    "\n",
    "Use Up/Down Arrow keys to increase or decrease volume.\n",
    "You can download the audio file from here.\n",
    "\n",
    "We will execute the below code for transcribing this audio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e2c407ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fbe17131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\monika201103\\Generative AI- OpenAI\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2617aba4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\monika201103\\\\Generative AI- OpenAI'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "152013fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hindi Hamari Matra Basha Hai. Sabhi Kehsa, Me Hindi and Navaria Honi Chahiye.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# opening the audio file in read mode\n",
    "audio_file = open(\"Play.ht - Untitled.wav\", \"rb\")\n",
    "# transcribing the audio file using Whisper-1 model\n",
    "transcript = openai.Audio.transcribe(\"whisper-1\", audio_file)\n",
    "# printing the transcript\n",
    "transcript['text']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a499d6",
   "metadata": {},
   "source": [
    "# Examples for Audio Translation\n",
    "We will execute the below code for translating this audio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "feed75e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hindi is our mother tongue. We should learn Hindi and Navarra.'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# opening the audio file in read mode\n",
    "audio_file= open(\"Play.ht - Untitled.wav\", \"rb\")\n",
    "# the input audio is in hindi language\n",
    "# translate module translates the input audio in English language\n",
    "transcript = openai.Audio.translate(\"whisper-1\", audio_file)\n",
    "# print the translated transcript\n",
    "transcript['text']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4868451d",
   "metadata": {},
   "source": [
    "# Embeddings\n",
    "The embeddings module is used to obtain a vector representation of a given input that machine learning models and algorithms can quickly consume. We will write a function to generate these vectors using OpenAI API. Our API employs the “text-embedding-ada-002” model, a member of OpenAI’s second generation of embedding models. This model produces embeddings that are 1536 bytes long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "084de10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to generate vector for a string\n",
    "def get_embedding(text, model=\"text-embedding-ada-002\"):\n",
    "    return openai.Embedding.create(input=text , model=model)['data'][0]['embedding']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7adf290",
   "metadata": {},
   "source": [
    "# Let’s try this out on some sample text.\n",
    "\n",
    "Prompt 1:|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4ad0d063",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.002129273721948266,\n",
       " -0.006914868950843811,\n",
       " -0.0023887434508651495,\n",
       " -0.034794893115758896,\n",
       " -0.010943137109279633,\n",
       " 0.01781259849667549,\n",
       " -0.003720147768035531,\n",
       " -0.009567947126924992,\n",
       " -0.020887315273284912,\n",
       " -0.0011003139661625028,\n",
       " 0.040607016533613205,\n",
       " -0.011325854808092117,\n",
       " 0.013648109510540962,\n",
       " -0.001320863259024918,\n",
       " -0.010839349590241909,\n",
       " -0.010638260282576084,\n",
       " 0.021068943664431572,\n",
       " -0.011189633049070835,\n",
       " 0.019914304837584496,\n",
       " -0.01580170914530754,\n",
       " -0.009678222239017487,\n",
       " -0.0034574344754219055,\n",
       " 0.021886274218559265,\n",
       " -0.01857803389430046,\n",
       " -0.0038466390687972307,\n",
       " 0.0007488135015591979,\n",
       " 0.00544886477291584,\n",
       " -0.012798345647752285,\n",
       " 0.0071743386797606945,\n",
       " -0.0041190823540091515,\n",
       " 0.019940251484513283,\n",
       " -0.004112595692276955,\n",
       " -0.0009908501524478197,\n",
       " -0.02131544053554535,\n",
       " -0.03334186226129532,\n",
       " -0.004093135241419077,\n",
       " 0.018149910494685173,\n",
       " 0.0003772446943912655,\n",
       " 0.02420852892100811,\n",
       " -0.022249531000852585,\n",
       " 0.026673492044210434,\n",
       " -0.007842473685741425,\n",
       " -0.007252179551869631,\n",
       " -0.015710894018411636,\n",
       " -0.009911744855344296,\n",
       " 0.02211979776620865,\n",
       " -0.0016670932527631521,\n",
       " -0.03064337931573391,\n",
       " -0.004644508473575115,\n",
       " 0.013544321060180664,\n",
       " 0.0011140982387587428,\n",
       " 0.012156158685684204,\n",
       " -0.03674091771245003,\n",
       " -0.018331538885831833,\n",
       " -0.012499955482780933,\n",
       " -0.016281727701425552,\n",
       " -0.004903978668153286,\n",
       " 0.02391013875603676,\n",
       " -0.002573615638539195,\n",
       " -0.023702561855316162,\n",
       " -0.018162883818149567,\n",
       " -0.007881393656134605,\n",
       " -0.008478173986077309,\n",
       " 0.004320171661674976,\n",
       " -0.009451186284422874,\n",
       " 0.009464159607887268,\n",
       " 0.0007666520541533828,\n",
       " -0.003489868249744177,\n",
       " -0.030487697571516037,\n",
       " -0.026530783623456955,\n",
       " 0.023793376982212067,\n",
       " 0.020679740235209465,\n",
       " -0.0053677805699408054,\n",
       " 0.012525903061032295,\n",
       " 0.00457964139059186,\n",
       " -0.0007273261435329914,\n",
       " 0.0007788147195242345,\n",
       " -0.00757003016769886,\n",
       " 0.006246734410524368,\n",
       " 0.001873047323897481,\n",
       " 0.014231916517019272,\n",
       " -0.037934478372335434,\n",
       " -0.009918231517076492,\n",
       " 0.013544321060180664,\n",
       " 0.009314964525401592,\n",
       " 0.020173773169517517,\n",
       " 0.015438450500369072,\n",
       " 0.020057013258337975,\n",
       " -0.02716648392379284,\n",
       " -0.01564602740108967,\n",
       " -0.014270836487412453,\n",
       " 0.01898021250963211,\n",
       " 0.03160341829061508,\n",
       " 0.018642902374267578,\n",
       " 0.00282984203658998,\n",
       " 0.043824441730976105,\n",
       " 0.025687506422400475,\n",
       " 0.010566906072199345,\n",
       " 0.012869699858129025,\n",
       " -0.025129646062850952,\n",
       " -0.0010678801918402314,\n",
       " 0.014932484365999699,\n",
       " -0.024312317371368408,\n",
       " -0.006940816063433886,\n",
       " -0.014815723523497581,\n",
       " -0.007933287881314754,\n",
       " 0.018409378826618195,\n",
       " -0.019901329651474953,\n",
       " 0.04143732041120529,\n",
       " -0.02215871773660183,\n",
       " -0.006622965447604656,\n",
       " 0.010988544672727585,\n",
       " 0.015788733959197998,\n",
       " -0.019693754613399506,\n",
       " -0.008705210871994495,\n",
       " -0.006214300636202097,\n",
       " 0.011235040612518787,\n",
       " 0.006914868950843811,\n",
       " -0.029501711949706078,\n",
       " -0.007719225250184536,\n",
       " 0.007823013700544834,\n",
       " -0.0001150383468484506,\n",
       " 0.02208087593317032,\n",
       " -0.011572351679205894,\n",
       " 0.019096974283456802,\n",
       " 0.009503079578280449,\n",
       " -0.02113381214439869,\n",
       " -0.016722826287150383,\n",
       " 0.018409378826618195,\n",
       " -0.01353134773671627,\n",
       " 0.01725473813712597,\n",
       " 0.007135418243706226,\n",
       " 0.034717053174972534,\n",
       " 0.01018418837338686,\n",
       " -0.022573869675397873,\n",
       " -0.004427202977240086,\n",
       " -0.0015884414315223694,\n",
       " 0.031032582744956017,\n",
       " -0.014711935073137283,\n",
       " -0.013155116699635983,\n",
       " 0.014387598261237144,\n",
       " 0.02044621668756008,\n",
       " 0.005915910471230745,\n",
       " -0.009321451187133789,\n",
       " -0.026336180046200752,\n",
       " 0.03090284764766693,\n",
       " 0.0196029394865036,\n",
       " -0.012370220385491848,\n",
       " 0.011870741844177246,\n",
       " 0.009301991201937199,\n",
       " 0.0005525894812308252,\n",
       " -0.011546404100954533,\n",
       " 0.003924480173736811,\n",
       " 0.013751897029578686,\n",
       " 0.010515011847019196,\n",
       " 0.01638551615178585,\n",
       " -0.016800666227936745,\n",
       " 0.009061980992555618,\n",
       " -0.020640820264816284,\n",
       " -0.011008004657924175,\n",
       " 0.006648912560194731,\n",
       " 0.008620882406830788,\n",
       " 0.009490106254816055,\n",
       " -0.010093373246490955,\n",
       " 0.005208855494856834,\n",
       " 0.032978605479002,\n",
       " 0.02976118214428425,\n",
       " -0.005069390404969454,\n",
       " -0.02103002369403839,\n",
       " 0.015438450500369072,\n",
       " -0.0029384950175881386,\n",
       " 0.03583277389407158,\n",
       " -0.01944725774228573,\n",
       " 0.008393846452236176,\n",
       " -0.0036196031142026186,\n",
       " 0.009094415232539177,\n",
       " -0.009924718178808689,\n",
       " -0.006434849929064512,\n",
       " -0.013194037601351738,\n",
       " -0.006661885883659124,\n",
       " -0.0017870980082079768,\n",
       " 0.004080161917954683,\n",
       " 0.011377749033272266,\n",
       " 0.025389116257429123,\n",
       " 0.008705210871994495,\n",
       " -0.002440637443214655,\n",
       " 0.007764632347971201,\n",
       " -0.010099860839545727,\n",
       " 0.010054453276097775,\n",
       " -0.01952509954571724,\n",
       " 0.0114620765671134,\n",
       " 0.012772399000823498,\n",
       " -0.0039309668354690075,\n",
       " -0.019395364448428154,\n",
       " -0.6634122729301453,\n",
       " -0.020095933228731155,\n",
       " 0.004709376022219658,\n",
       " -0.01741042174398899,\n",
       " -0.011786413379013538,\n",
       " 0.010962597094476223,\n",
       " 0.009029547683894634,\n",
       " 0.03762311488389969,\n",
       " -0.009723628871142864,\n",
       " 0.0021130568347871304,\n",
       " 0.004926681984215975,\n",
       " 0.02044621668756008,\n",
       " 0.0024633409921079874,\n",
       " -0.001778989564627409,\n",
       " -0.01602225750684738,\n",
       " -0.028100574389100075,\n",
       " -0.016489302739501,\n",
       " -0.006619722116738558,\n",
       " 0.01777367852628231,\n",
       " -0.003700687550008297,\n",
       " -0.019680781289935112,\n",
       " 0.011981016024947166,\n",
       " -0.009483619593083858,\n",
       " -0.0028525455854833126,\n",
       " 0.019862409681081772,\n",
       " 0.015425477176904678,\n",
       " 0.014296784065663815,\n",
       " -0.01469896174967289,\n",
       " -0.0033828369341790676,\n",
       " 0.01344053354114294,\n",
       " -0.03248561546206474,\n",
       " -3.9275209928746335e-06,\n",
       " 0.0009486863273195922,\n",
       " -0.0019346714252606034,\n",
       " 0.03946534916758537,\n",
       " -0.0015276281628757715,\n",
       " -0.0205110851675272,\n",
       " 0.02189924754202366,\n",
       " -0.0014805992832407355,\n",
       " 0.035080309957265854,\n",
       " -0.014621120877563953,\n",
       " -0.019395364448428154,\n",
       " 0.006344035733491182,\n",
       " -0.01411515474319458,\n",
       " -0.025583717972040176,\n",
       " 0.0015073571121320128,\n",
       " 0.014037313871085644,\n",
       " -0.0007703008595854044,\n",
       " -0.00841330736875534,\n",
       " 0.007278126664459705,\n",
       " 0.00974308978766203,\n",
       " -0.002894709585234523,\n",
       " -0.011916148476302624,\n",
       " 0.011111792176961899,\n",
       " 0.019317524507641792,\n",
       " -0.00864682998508215,\n",
       " 0.020796502009034157,\n",
       " 0.008328978903591633,\n",
       " 0.009081441909074783,\n",
       " 0.006908382289111614,\n",
       " 0.00662945257499814,\n",
       " 0.028204362839460373,\n",
       " -0.029890915378928185,\n",
       " -0.01689148135483265,\n",
       " -0.03489868342876434,\n",
       " -0.013479454442858696,\n",
       " -0.018565060570836067,\n",
       " -0.016333620995283127,\n",
       " -0.011455589905381203,\n",
       " -0.00283795059658587,\n",
       " 0.03572898730635643,\n",
       " 0.0032871575094759464,\n",
       " -0.010722587816417217,\n",
       " 0.03173315152525902,\n",
       " 0.007842473685741425,\n",
       " 0.03072121925652027,\n",
       " 0.008938733488321304,\n",
       " -0.0035125717986375093,\n",
       " 0.007725711911916733,\n",
       " -0.004858571104705334,\n",
       " 0.010780968703329563,\n",
       " -0.000520561181474477,\n",
       " 0.0017238522414118052,\n",
       " 0.003577439347282052,\n",
       " -0.00026737546431832016,\n",
       " -0.038012318313121796,\n",
       " -0.032745081931352615,\n",
       " 5.7975274103228e-05,\n",
       " 0.020134853199124336,\n",
       " 0.0055948165245354176,\n",
       " 0.02000511810183525,\n",
       " 0.003911506850272417,\n",
       " 0.00928901694715023,\n",
       " -0.007420835085213184,\n",
       " -0.002072514733299613,\n",
       " 0.019032107666134834,\n",
       " -0.009587408043444157,\n",
       " 0.02300199493765831,\n",
       " 0.014582200907170773,\n",
       " -0.011332341469824314,\n",
       " 0.0030341744422912598,\n",
       " -0.030773112550377846,\n",
       " 0.0335753858089447,\n",
       " -0.004780730232596397,\n",
       " 0.011909661814570427,\n",
       " 0.008867379277944565,\n",
       " -0.013427560217678547,\n",
       " 0.030254174023866653,\n",
       " 0.01612604595720768,\n",
       " -0.0011886957800015807,\n",
       " -0.002584967529401183,\n",
       " -0.029864968731999397,\n",
       " -0.025752373039722443,\n",
       " -0.0019817003048956394,\n",
       " -0.0019427798688411713,\n",
       " -0.027451900765299797,\n",
       " 0.011248013935983181,\n",
       " 0.017566103488206863,\n",
       " -0.0043590920977294445,\n",
       " 0.003538518911227584,\n",
       " -0.008932246826589108,\n",
       " 0.011494509875774384,\n",
       " 0.017721785232424736,\n",
       " 0.004012051038444042,\n",
       " 0.01460814755409956,\n",
       " -0.011442616581916809,\n",
       " -0.005439134780317545,\n",
       " -0.010845836251974106,\n",
       " -0.04250114783644676,\n",
       " 0.004109352361410856,\n",
       " -0.005143987946212292,\n",
       " -0.020355403423309326,\n",
       " -0.007861933670938015,\n",
       " -0.01469896174967289,\n",
       " 0.004287737887352705,\n",
       " 0.017397446557879448,\n",
       " 0.006483500823378563,\n",
       " -0.023637695237994194,\n",
       " 0.013505401089787483,\n",
       " -0.009574433788657188,\n",
       " -0.009334424510598183,\n",
       " -0.01879858411848545,\n",
       " 0.011896688491106033,\n",
       " 0.011565864086151123,\n",
       " -0.00658080168068409,\n",
       " 0.014841670170426369,\n",
       " -0.024948017671704292,\n",
       " -0.022729551419615746,\n",
       " -0.019693754613399506,\n",
       " 0.005497515667229891,\n",
       " 0.008056536316871643,\n",
       " 0.0048034340143203735,\n",
       " -0.0033244562800973654,\n",
       " 0.0035547357983887196,\n",
       " 0.02022566832602024,\n",
       " -0.02314470335841179,\n",
       " -0.009658762253820896,\n",
       " -0.02833409793674946,\n",
       " -0.006220787297934294,\n",
       " -5.701239933841862e-05,\n",
       " -0.007258666679263115,\n",
       " -0.018928319215774536,\n",
       " -0.009477132931351662,\n",
       " 0.0018989943200722337,\n",
       " -0.008140863850712776,\n",
       " -0.0012235620524734259,\n",
       " 0.006901895627379417,\n",
       " 0.034379743039608,\n",
       " -0.014283809810876846,\n",
       " -0.02823030948638916,\n",
       " 0.005708334501832724,\n",
       " -0.007634897716343403,\n",
       " -0.024519892409443855,\n",
       " -0.016593091189861298,\n",
       " -0.016281727701425552,\n",
       " 0.0022833338007330894,\n",
       " -0.0017465557903051376,\n",
       " -0.003528788685798645,\n",
       " -0.014621120877563953,\n",
       " -0.023871218785643578,\n",
       " -0.007342994213104248,\n",
       " 0.014491385780274868,\n",
       " -0.0016395245911553502,\n",
       " 0.011131253093481064,\n",
       " 0.04325360804796219,\n",
       " 0.0012762668775394559,\n",
       " 0.04278656467795372,\n",
       " 0.021107865497469902,\n",
       " -0.006862975191324949,\n",
       " -0.001158694620244205,\n",
       " 0.003112015314400196,\n",
       " 0.02595994994044304,\n",
       " -0.03287481889128685,\n",
       " -0.015386556275188923,\n",
       " 0.03521004691720009,\n",
       " 0.012785372324287891,\n",
       " 0.015568185597658157,\n",
       " -0.01137126237154007,\n",
       " 0.01018418837338686,\n",
       " 0.014400571584701538,\n",
       " 0.01630767434835434,\n",
       " 0.0003565681981854141,\n",
       " 0.013894605450332165,\n",
       " -0.011105305515229702,\n",
       " 0.021237600594758987,\n",
       " -0.032563455402851105,\n",
       " 0.016359567642211914,\n",
       " -0.03240777179598808,\n",
       " 0.021484095603227615,\n",
       " 0.015075192786753178,\n",
       " 0.007355967536568642,\n",
       " -0.008374386467039585,\n",
       " 0.011105305515229702,\n",
       " 0.00272443238645792,\n",
       " 0.01416704896837473,\n",
       " 0.0058802333660423756,\n",
       " -0.023066861554980278,\n",
       " 0.02903466671705246,\n",
       " -0.00866628997027874,\n",
       " -0.009386318735778332,\n",
       " 0.009029547683894634,\n",
       " 0.01905805431306362,\n",
       " 0.019693754613399506,\n",
       " 0.00804356299340725,\n",
       " -0.008594935759902,\n",
       " 0.019979171454906464,\n",
       " 0.025064779445528984,\n",
       " 0.03401648625731468,\n",
       " 0.0002568345225881785,\n",
       " -0.02706269547343254,\n",
       " -0.002745514502748847,\n",
       " 0.0005627250648103654,\n",
       " -0.009003601036965847,\n",
       " 0.028878984972834587,\n",
       " -0.0024455024395138025,\n",
       " -0.00934091117233038,\n",
       " 0.008108429610729218,\n",
       " -0.02589508146047592,\n",
       " 0.04032159969210625,\n",
       " -0.00548454187810421,\n",
       " -0.025220461189746857,\n",
       " 0.019187789410352707,\n",
       " 0.023923112079501152,\n",
       " -0.028074627742171288,\n",
       " 0.010262029245495796,\n",
       " 0.018526140600442886,\n",
       " 0.01604820415377617,\n",
       " 0.011248013935983181,\n",
       " -0.022145744413137436,\n",
       " 0.03788258507847786,\n",
       " -0.018435325473546982,\n",
       " -0.01495843194425106,\n",
       " 0.006253221072256565,\n",
       " 0.0048780315555632114,\n",
       " 0.023053888231515884,\n",
       " 0.0009389562183059752,\n",
       " 0.01013229414820671,\n",
       " 0.003940696828067303,\n",
       " 0.018603982403874397,\n",
       " 0.011572351679205894,\n",
       " -0.012850239872932434,\n",
       " 0.003973130602389574,\n",
       " 0.026569703593850136,\n",
       " -0.012720504775643349,\n",
       " -0.009146309457719326,\n",
       " 0.007291100453585386,\n",
       " -0.00672026677057147,\n",
       " 0.00617213686928153,\n",
       " -0.00969119556248188,\n",
       " -0.002197384601458907,\n",
       " -0.00255577708594501,\n",
       " -0.02055000513792038,\n",
       " 0.0011562621220946312,\n",
       " 0.015412503853440285,\n",
       " -0.0030017406679689884,\n",
       " 0.01031392253935337,\n",
       " 0.012493468821048737,\n",
       " 0.001646011252887547,\n",
       " -0.0026611867360770702,\n",
       " 0.018993185833096504,\n",
       " -0.0032871575094759464,\n",
       " -0.02662159688770771,\n",
       " 0.0136221619322896,\n",
       " 0.003303374396637082,\n",
       " 0.00463477848097682,\n",
       " 0.00010044317605206743,\n",
       " 0.0009470646036788821,\n",
       " -0.006078079342842102,\n",
       " 0.0036747404374182224,\n",
       " 0.0070316302590072155,\n",
       " -0.019914304837584496,\n",
       " 0.043201714754104614,\n",
       " -0.013712977059185505,\n",
       " -0.004741809796541929,\n",
       " -0.006707293447107077,\n",
       " -0.005769958719611168,\n",
       " 0.00408664857968688,\n",
       " -0.0034963549114763737,\n",
       " -0.012318327091634274,\n",
       " 0.01460814755409956,\n",
       " -0.009574433788657188,\n",
       " -0.007077037822455168,\n",
       " -0.010333383455872536,\n",
       " -0.02555777132511139,\n",
       " 0.007848960347473621,\n",
       " -0.004702889360487461,\n",
       " 0.007511649746447802,\n",
       " -0.027374058961868286,\n",
       " -0.016865534707903862,\n",
       " -0.039880502969026566,\n",
       " -0.003736364422366023,\n",
       " 0.012058856897056103,\n",
       " -0.009301991201937199,\n",
       " -0.00245036743581295,\n",
       " -0.004647752270102501,\n",
       " -0.006065105553716421,\n",
       " -0.011033951304852962,\n",
       " -0.0176958367228508,\n",
       " 0.027477847412228584,\n",
       " 0.017034189775586128,\n",
       " 0.015516291372478008,\n",
       " -0.01602225750684738,\n",
       " -0.02527235448360443,\n",
       " -0.00017656106501817703,\n",
       " 0.10451442003250122,\n",
       " 0.03188883513212204,\n",
       " 0.006726753432303667,\n",
       " 0.009334424510598183,\n",
       " 0.013881632126867771,\n",
       " -0.0004913708544336259,\n",
       " -0.028878984972834587,\n",
       " -0.028619514778256416,\n",
       " 0.0012316704960539937,\n",
       " -0.01693040132522583,\n",
       " 0.0031866130884736776,\n",
       " 0.013777844607830048,\n",
       " 0.007634897716343403,\n",
       " 0.013661082834005356,\n",
       " 0.013310798443853855,\n",
       " 0.012480495497584343,\n",
       " 0.0011651813983917236,\n",
       " 0.00014483682753052562,\n",
       " 0.0018341268878430128,\n",
       " -0.016554171219468117,\n",
       " -0.004099622368812561,\n",
       " 0.001573846209794283,\n",
       " -0.01089772954583168,\n",
       " -0.009788496419787407,\n",
       " 0.009678222239017487,\n",
       " 0.021302467212080956,\n",
       " 0.01948617957532406,\n",
       " 0.007278126664459705,\n",
       " -0.013725950382649899,\n",
       " -0.015697920694947243,\n",
       " -0.019914304837584496,\n",
       " 0.0007034062873572111,\n",
       " 0.00509209418669343,\n",
       " -0.0042163836769759655,\n",
       " 0.0048488411121070385,\n",
       " 0.021561937406659126,\n",
       " -0.020095933228731155,\n",
       " 0.028126521036028862,\n",
       " 0.005971048027276993,\n",
       " -0.009464159607887268,\n",
       " 0.008581962436437607,\n",
       " 0.015010325238108635,\n",
       " 0.007161365356296301,\n",
       " -0.023819323629140854,\n",
       " 0.020277561619877815,\n",
       " 0.0009227393311448395,\n",
       " 0.0019752136431634426,\n",
       " 0.045329365879297256,\n",
       " 0.009820930659770966,\n",
       " -0.019499152898788452,\n",
       " 0.025609664618968964,\n",
       " -0.007090011145919561,\n",
       " -0.019836463034152985,\n",
       " -0.019940251484513283,\n",
       " 0.007965721189975739,\n",
       " -0.001144910347647965,\n",
       " -0.005027226638048887,\n",
       " -0.016411462798714638,\n",
       " -0.009976612403988838,\n",
       " -0.009626328013837337,\n",
       " -0.0102555425837636,\n",
       " -0.004926681984215975,\n",
       " 0.013570268638432026,\n",
       " 0.010417710989713669,\n",
       " -0.02032945491373539,\n",
       " -0.04200815409421921,\n",
       " -0.0016103341476991773,\n",
       " 0.0021422472782433033,\n",
       " -0.013057815842330456,\n",
       " -0.0058640167117118835,\n",
       " 0.00467045558616519,\n",
       " -0.030695272609591484,\n",
       " -0.027192430570721626,\n",
       " 0.00043907147482968867,\n",
       " 0.025181539356708527,\n",
       " 0.009496592916548252,\n",
       " 0.016100099310278893,\n",
       " 0.010515011847019196,\n",
       " -0.008659803308546543,\n",
       " 0.006798107642680407,\n",
       " 0.0015243848320096731,\n",
       " -0.03671497106552124,\n",
       " -0.0010289597557857633,\n",
       " -0.0102555425837636,\n",
       " 0.0036358200013637543,\n",
       " 0.02921629510819912,\n",
       " 0.0011659922311082482,\n",
       " 0.009911744855344296,\n",
       " -0.005857530049979687,\n",
       " 0.004550450947135687,\n",
       " 0.022262506186962128,\n",
       " 0.02153599075973034,\n",
       " 0.016502276062965393,\n",
       " -0.024234475567936897,\n",
       " 0.006201327312737703,\n",
       " 0.024156633764505386,\n",
       " 0.01777367852628231,\n",
       " 0.007154878694564104,\n",
       " -0.013907578773796558,\n",
       " -0.007284613326191902,\n",
       " -0.011020977981388569,\n",
       " -0.019551046192646027,\n",
       " 0.009587408043444157,\n",
       " -0.018266670405864716,\n",
       " -0.020718660205602646,\n",
       " 0.007090011145919561,\n",
       " 0.0005075877415947616,\n",
       " -0.004070431925356388,\n",
       " -0.023572826758027077,\n",
       " -0.004861814435571432,\n",
       " 0.025908054783940315,\n",
       " -0.014218943193554878,\n",
       " 0.019901329651474953,\n",
       " -0.01912292093038559,\n",
       " 0.010975570417940617,\n",
       " 0.03227803856134415,\n",
       " 0.04618561640381813,\n",
       " 0.00641863327473402,\n",
       " -0.007161365356296301,\n",
       " -0.015127087011933327,\n",
       " 0.015321689657866955,\n",
       " -0.04942898824810982,\n",
       " 0.011851280927658081,\n",
       " -0.0019508881960064173,\n",
       " -0.02416960895061493,\n",
       " 0.0038725861813873053,\n",
       " 0.0060975393280386925,\n",
       " -0.03284887224435806,\n",
       " 0.018085042014718056,\n",
       " -0.00848466157913208,\n",
       " -0.032174251973629,\n",
       " -7.398942398140207e-05,\n",
       " -0.02567453309893608,\n",
       " -0.03129205480217934,\n",
       " -0.0432276614010334,\n",
       " -0.021068943664431572,\n",
       " 0.0014497872907668352,\n",
       " 0.007959234528243542,\n",
       " -0.0032060733065009117,\n",
       " -0.008763590827584267,\n",
       " -0.03985455632209778,\n",
       " -0.0011246391804888844,\n",
       " -0.00461531849578023,\n",
       " 0.007673818152397871,\n",
       " -0.05687577277421951,\n",
       " -0.026673492044210434,\n",
       " 0.017942333593964577,\n",
       " 0.005487785208970308,\n",
       " -0.012097777798771858,\n",
       " 0.01234427373856306,\n",
       " -0.02991686388850212,\n",
       " 0.013505401089787483,\n",
       " -0.001221129554323852,\n",
       " -0.012331300415098667,\n",
       " -0.019680781289935112,\n",
       " -0.036870650947093964,\n",
       " -0.013648109510540962,\n",
       " 0.01013229414820671,\n",
       " 0.023157676681876183,\n",
       " 0.0038271788507699966,\n",
       " 0.028515726327896118,\n",
       " 0.013946499675512314,\n",
       " 0.017981253564357758,\n",
       " -0.004093135241419077,\n",
       " -0.006888922303915024,\n",
       " -0.0031817478593438864,\n",
       " 0.019071027636528015,\n",
       " -0.006522421259433031,\n",
       " -0.01663201116025448,\n",
       " 0.0024390157777816057,\n",
       " 0.01568494737148285,\n",
       " 0.013712977059185505,\n",
       " 0.012227511964738369,\n",
       " 0.014270836487412453,\n",
       " -0.003282292513176799,\n",
       " 0.014257863163948059,\n",
       " 0.007725711911916733,\n",
       " 0.0019184545380994678,\n",
       " -0.01022310834378004,\n",
       " -0.05474811792373657,\n",
       " -0.007621924392879009,\n",
       " 0.008860892616212368,\n",
       " -0.008543041534721851,\n",
       " -0.004080161917954683,\n",
       " 0.00983390398323536,\n",
       " -0.019680781289935112,\n",
       " 0.023520933464169502,\n",
       " 0.0015584402717649937,\n",
       " -0.0007597599178552628,\n",
       " -0.008815485052764416,\n",
       " 0.029605500400066376,\n",
       " 0.0037071742117404938,\n",
       " 0.003879072843119502,\n",
       " -0.004754783120006323,\n",
       " 0.04039944335818291,\n",
       " -0.00488127488642931,\n",
       " -0.006259707733988762,\n",
       " -0.016320647671818733,\n",
       " 0.006522421259433031,\n",
       " 0.0005266425432637334,\n",
       " 0.011014491319656372,\n",
       " 0.00891927257180214,\n",
       " -0.0018973726546391845,\n",
       " 0.011293421499431133,\n",
       " 0.02055000513792038,\n",
       " 0.00817329715937376,\n",
       " -0.006804594304412603,\n",
       " -0.005215342156589031,\n",
       " -0.012610230594873428,\n",
       " 0.006094295997172594,\n",
       " -0.002385500119999051,\n",
       " -0.023741483688354492,\n",
       " -0.030254174023866653,\n",
       " -0.0050888508558273315,\n",
       " 0.00688243517652154,\n",
       " -0.02022566832602024,\n",
       " -0.006464040372520685,\n",
       " 0.012266432866454124,\n",
       " 0.0038855597376823425,\n",
       " -0.019291575998067856,\n",
       " 0.0001938928326126188,\n",
       " -0.0012997813755646348,\n",
       " 0.03910209238529205,\n",
       " 0.0069862231612205505,\n",
       " 0.01264915056526661,\n",
       " 0.01667093113064766,\n",
       " 0.01733257994055748,\n",
       " 0.02169167250394821,\n",
       " 0.003697443986311555,\n",
       " 0.0032968877349048853,\n",
       " 0.0028314637020230293,\n",
       " 0.01678769290447235,\n",
       " 0.011877228505909443,\n",
       " -0.0009219284984283149,\n",
       " -0.0031639093067497015,\n",
       " -0.008672776632010937,\n",
       " -0.015568185597658157,\n",
       " 0.011436129920184612,\n",
       " -0.013414586894214153,\n",
       " -0.0048488411121070385,\n",
       " 0.00679162098094821,\n",
       " -0.012071830220520496,\n",
       " -0.013738923706114292,\n",
       " 0.017540154978632927,\n",
       " -0.02732216566801071,\n",
       " 0.026375101879239082,\n",
       " 0.007887880317866802,\n",
       " 0.014335704036056995,\n",
       " -0.02330038510262966,\n",
       " 0.0024325288832187653,\n",
       " -0.0313698947429657,\n",
       " 0.00365203688852489,\n",
       " 0.00378501508384943,\n",
       " 0.02618049830198288,\n",
       " 0.012603743933141232,\n",
       " 0.012156158685684204,\n",
       " 0.004248817451298237,\n",
       " -0.010359330102801323,\n",
       " 0.005724551621824503,\n",
       " 0.007115958258509636,\n",
       " -0.012499955482780933,\n",
       " 0.0012908620992675424,\n",
       " -0.02044621668756008,\n",
       " 0.01089772954583168,\n",
       " -0.013985419645905495,\n",
       " 0.015166006982326508,\n",
       " -0.007310560438781977,\n",
       " 0.0010443658102303743,\n",
       " 0.01052798517048359,\n",
       " 0.019615914672613144,\n",
       " -0.01358324196189642,\n",
       " -0.005247775930911303,\n",
       " -0.02073163352906704,\n",
       " 0.012285892851650715,\n",
       " 0.013505401089787483,\n",
       " 0.010151754133403301,\n",
       " -2.1322637621778995e-05,\n",
       " 0.006311601959168911,\n",
       " -0.01455625332891941,\n",
       " -0.0009503079927526414,\n",
       " 0.024818282574415207,\n",
       " -0.005964560899883509,\n",
       " -0.022573869675397873,\n",
       " 0.009587408043444157,\n",
       " -0.00276010949164629,\n",
       " 0.0022184664849191904,\n",
       " -0.010579879395663738,\n",
       " -0.005734281614422798,\n",
       " 0.008075996302068233,\n",
       " -0.018526140600442886,\n",
       " -0.005740768276154995,\n",
       " -0.036507394164800644,\n",
       " 0.018227750435471535,\n",
       " 0.01128044817596674,\n",
       " 0.009113875217735767,\n",
       " -0.004362335428595543,\n",
       " 0.018603982403874397,\n",
       " 0.008562502451241016,\n",
       " 0.0010419331956654787,\n",
       " 0.0014084342401474714,\n",
       " 0.01020364835858345,\n",
       " 0.02654375694692135,\n",
       " -0.031032582744956017,\n",
       " 0.01642443612217903,\n",
       " -0.003927723504602909,\n",
       " -0.02479233592748642,\n",
       " 0.02252197451889515,\n",
       " -0.021068943664431572,\n",
       " -0.02187330089509487,\n",
       " -0.03767500817775726,\n",
       " 0.001395460800267756,\n",
       " 0.0019541315268725157,\n",
       " -0.02368958853185177,\n",
       " -0.009152796119451523,\n",
       " -0.013959472998976707,\n",
       " 0.02651781029999256,\n",
       " 0.017786651849746704,\n",
       " -0.00041413804865442216,\n",
       " -0.03401648625731468,\n",
       " 0.010463117621839046,\n",
       " -0.0197067279368639,\n",
       " -0.007855447009205818,\n",
       " 0.005374267231673002,\n",
       " -0.003045526333153248,\n",
       " -0.003522302024066448,\n",
       " 0.018072068691253662,\n",
       " 0.02241818793118,\n",
       " -0.0023400927893817425,\n",
       " -0.014724908396601677,\n",
       " -0.017241764813661575,\n",
       " 0.0012081561144441366,\n",
       " -0.0034282442647963762,\n",
       " 0.006259707733988762,\n",
       " -0.008075996302068233,\n",
       " -0.008400333113968372,\n",
       " -0.008037075400352478,\n",
       " -0.008744130842387676,\n",
       " 0.013738923706114292,\n",
       " 0.009308477863669395,\n",
       " 0.027841106057167053,\n",
       " -0.0011870741145685315,\n",
       " 0.03074716590344906,\n",
       " 0.0008063833811320364,\n",
       " 0.02201600931584835,\n",
       " -0.016839588060975075,\n",
       " -0.013310798443853855,\n",
       " -0.02778921090066433,\n",
       " -0.01029446255415678,\n",
       " -0.04413580521941185,\n",
       " -0.018422352150082588,\n",
       " -0.008497634902596474,\n",
       " 0.00645431037992239,\n",
       " -0.00044150400208309293,\n",
       " -0.0249350443482399,\n",
       " -0.02672538533806801,\n",
       " -0.020459190011024475,\n",
       " -0.03002065047621727,\n",
       " -0.01638551615178585,\n",
       " 0.002894709585234523,\n",
       " 0.0017449341248720884,\n",
       " 0.022145744413137436,\n",
       " 0.012967001646757126,\n",
       " -0.0045018005184829235,\n",
       " 0.014543280005455017,\n",
       " 0.0014181643491610885,\n",
       " 0.01013229414820671,\n",
       " -0.014724908396601677,\n",
       " 0.009172256104648113,\n",
       " 0.01982348971068859,\n",
       " -0.00679162098094821,\n",
       " -0.0051277712918818,\n",
       " -0.013064302504062653,\n",
       " 0.0026271312963217497,\n",
       " -0.0120653435587883,\n",
       " 0.007511649746447802,\n",
       " 0.0022671169135719538,\n",
       " -0.027841106057167053,\n",
       " 0.010761508718132973,\n",
       " 0.027114590629935265,\n",
       " -0.015529264695942402,\n",
       " 0.00014919511158950627,\n",
       " -0.012571309693157673,\n",
       " 0.010210135020315647,\n",
       " 0.012006962671875954,\n",
       " -0.005332103464752436,\n",
       " -0.025752373039722443,\n",
       " -0.014802750200033188,\n",
       " 0.009749576449394226,\n",
       " 0.027581635862588882,\n",
       " -0.01689148135483265,\n",
       " -0.0020887316204607487,\n",
       " 0.030617430806159973,\n",
       " -0.018020175397396088,\n",
       " 0.01908400095999241,\n",
       " -0.02468854747712612,\n",
       " -0.01777367852628231,\n",
       " 0.02991686388850212,\n",
       " 0.01446543913334608,\n",
       " 0.017319606617093086,\n",
       " -0.008497634902596474,\n",
       " -0.013687029480934143,\n",
       " 0.010171214118599892,\n",
       " 0.02022566832602024,\n",
       " -0.01250644214451313,\n",
       " 0.0061137559823691845,\n",
       " 0.008718184195458889,\n",
       " -0.029864968731999397,\n",
       " 0.0034120273776352406,\n",
       " 0.019849436357617378,\n",
       " -0.04200815409421921,\n",
       " -0.02471449412405491,\n",
       " 0.004401255864650011,\n",
       " -0.0029449816793203354,\n",
       " -0.03725985810160637,\n",
       " -0.011384235695004463,\n",
       " -0.025363169610500336,\n",
       " 0.015399530529975891,\n",
       " -0.030487697571516037,\n",
       " 0.02058892510831356,\n",
       " 0.031058529391884804,\n",
       " -0.024338264018297195,\n",
       " 0.005432648118585348,\n",
       " -0.024442050606012344,\n",
       " -0.019551046192646027,\n",
       " -0.0033082393929362297,\n",
       " -0.02559669129550457,\n",
       " -0.0073624541983008385,\n",
       " -0.007187312468886375,\n",
       " -0.013077275827527046,\n",
       " 0.016074150800704956,\n",
       " -0.021510042250156403,\n",
       " -0.04224167764186859,\n",
       " 0.0028557891491800547,\n",
       " 0.012058856897056103,\n",
       " 0.01029446255415678,\n",
       " 0.011539917439222336,\n",
       " 0.2376742959022522,\n",
       " 0.0008019237429834902,\n",
       " -0.00971065554767847,\n",
       " 0.026011843234300613,\n",
       " -0.006318088620901108,\n",
       " 0.019032107666134834,\n",
       " 0.004037998151034117,\n",
       " -0.0008594935643486679,\n",
       " -0.002992010675370693,\n",
       " 0.016995269805192947,\n",
       " -0.01255833636969328,\n",
       " -0.006120243109762669,\n",
       " -0.03396459296345711,\n",
       " 0.007524623069912195,\n",
       " -0.01580170914530754,\n",
       " -0.03261534869670868,\n",
       " -0.02672538533806801,\n",
       " -0.03090284764766693,\n",
       " -0.016100099310278893,\n",
       " -0.004372065421193838,\n",
       " 0.02058892510831356,\n",
       " 0.01376487035304308,\n",
       " 0.031162317842245102,\n",
       " -0.019615914672613144,\n",
       " 0.03495057672262192,\n",
       " 0.021951140835881233,\n",
       " -0.011507484130561352,\n",
       " -0.0027763263788074255,\n",
       " 0.04727539047598839,\n",
       " 0.02545398287475109,\n",
       " 0.00987282395362854,\n",
       " 0.0032385068479925394,\n",
       " 0.009717142209410667,\n",
       " -0.017488261684775352,\n",
       " 0.020069986581802368,\n",
       " 0.008497634902596474,\n",
       " 0.008984140120446682,\n",
       " -0.01755312830209732,\n",
       " 0.01741042174398899,\n",
       " 0.011098818853497505,\n",
       " -0.0056077903136610985,\n",
       " -0.006914868950843811,\n",
       " -0.02716648392379284,\n",
       " -0.015516291372478008,\n",
       " 0.008530068211257458,\n",
       " -0.010411224327981472,\n",
       " ...]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PROMPT = \"This is Geeks for Geeks office. How can I help you?\"\n",
    "get_embedding(PROMPT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0328c091",
   "metadata": {},
   "source": [
    "As we can see, we have obtained a vector generated by OpenAI Embeddings module. You can use this vector with any machine learning or deep learning algorithm.\n",
    "\n",
    "Fine-Tuning\n",
    "Open AI allows developers to fine-tune their models for specific purposes using their fine-tunes API endpoint. Below listed are the models you can fine-tune using this API:\n",
    "\n",
    "davinci\n",
    "curie\n",
    "babbage\n",
    "ada\n",
    "For fine-tuning a model, you first need to make sure that your dataset is in JSONL format and if you are working on free trial, your training bill should not exceed 5 dollars. To prepare your dataset, you can execute the below command in your jupyter notebook:\n",
    "\n",
    "!openai tools fine_tunes.prepare_data -f <dataset location>\n",
    "\n",
    "With the exception of a prompt and a completion column/key, this tool accepts a variety of forms. You can instruct it to store the output into a JSONL file suitable for fine-tuning by passing it a CSV, TSV, XLSX, JSON, or JSONL file. It will walk you through the process of proposed adjustments.\n",
    "\n",
    "Now, you can fine-tune a model by executing the below code in python environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fbb0a947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing...\n",
      "\n",
      "- Based on your file extension, your file is formatted as a CSV file\n",
      "- Your file contains 3994 prompt-completion pairs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ERROR in necessary_column validator: `prompt` column/key is missing. Please make sure you name your columns/keys appropriately, then retry\n",
      "\n",
      "Aborting...\n"
     ]
    }
   ],
   "source": [
    "!openai tools fine_tunes.prepare_data -f \"AmericaBankNew.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "499f3ba5",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "expression cannot contain assignment, perhaps you meant \"==\"? (2463362539.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[69], line 3\u001b[1;36m\u001b[0m\n\u001b[1;33m    res = openai.FineTune.create(\"training_file\"=\"<training-file-id>\",\u001b[0m\n\u001b[1;37m                                 ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m expression cannot contain assignment, perhaps you meant \"==\"?\n"
     ]
    }
   ],
   "source": [
    "# FineTune Endpoint of OpenAI is used to fine-tune models\n",
    "# for a specific task\n",
    "res = openai.FineTune.create(\"training_file\"=\"<training-file-id>\",\n",
    "\t\"validation_file\"=\"<validation-file-id>\",\n",
    "\t\"model\"==\"<model-name>\",\n",
    "\t\"n_epochs\"==\"<number of epochs/iterations>[integer]\",\n",
    "\t\"batch_size\"==\"<batch size for model to train on>[integer]\",\n",
    "\t\"learning_rate_multiplier\"==\"\"\"<The pretraining learning rate multiplied by this\n",
    "\tnumber yields the fine-tuning learning rate.>[integer]\"\"\")\n",
    "# storing the fine-tuning Job ID\n",
    "jobID = res[\"id\"]\n",
    "# storing the status of fine-tuning\n",
    "# initially it will show pending that means your task is in the queue\n",
    "status = res[\"status\"]\n",
    "\n",
    "print(f'Fine-tunning model with jobID: {jobID}.')\n",
    "print(f\"Training Response: {res}\")\n",
    "print(f\"Training Status: {status}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2f165f",
   "metadata": {},
   "source": [
    "Example of Fine-tuning\n",
    "We will be taking the first 100 rows of Spam Classification dataset here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d3b79b4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing...\n",
      "\n",
      "- Based on your file extension, your file is formatted as a CSV file\n",
      "- Your file contains 3994 prompt-completion pairs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ERROR in necessary_column validator: `prompt` column/key is missing. Please make sure you name your columns/keys appropriately, then retry\n",
      "\n",
      "Aborting...\n"
     ]
    }
   ],
   "source": [
    "!openai tools fine_tunes.prepare_data -f \"AmericaBankNew.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d1a53388",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'spam_prepared_train.jsonl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[60], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# uploading the training dataset\u001b[39;00m\n\u001b[0;32m      2\u001b[0m openai\u001b[38;5;241m.\u001b[39mFile\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m----> 3\u001b[0m file\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mspam_prepared_train.jsonl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m,\n\u001b[0;32m      4\u001b[0m purpose\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfine-tune\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      5\u001b[0m )\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\Torch\\lib\\site-packages\\IPython\\core\\interactiveshell.py:284\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    279\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    280\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    281\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    282\u001b[0m     )\n\u001b[1;32m--> 284\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'spam_prepared_train.jsonl'"
     ]
    }
   ],
   "source": [
    "# uploading the training dataset\n",
    "openai.File.create(\n",
    "file=open(\"spam_prepared_train.jsonl\", \"rb\"),\n",
    "purpose='fine-tune'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90da119d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
